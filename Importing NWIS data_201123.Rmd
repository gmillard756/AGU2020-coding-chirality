---
title: "Playing with lesson 2-py"
author: "Geoffrey Millard"
date: "November 4, 2020"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(kableExtra)
pltr <- import('matplotlib')
pltr$use("Agg", force = TRUE)
py_discover_config()
use_python('C:/Users/gmill/AppData/Local/r-miniconda/envs/r-reticulate/python.exe')
# virtualenv_install(envname = 'AGU2020', packages = c('matplotlib', 'dataretrieval', 'SciPy'))
# virtualenv_python()
# virtualenv_list()
# use_virtualenv('AGU2020')

# conda_list()
# conda_python()
# 
# miniconda_path()

# conda_install(envname = 'AGU2020', packages = 'git')
# conda_install(envname = 'AGU2020', packages = 'pip')
# conda_install(envname = 'AGU2020', packages = 'dataretrieval', url = 'git+git://github.com/USGS-python/dataretrieval.git')
use_condaenv(condaenv = 'AGU2020')


# conda_install(envname = 'AGU2020', packages = c('SciPy', 'NumPy', 'matplotlib', 'dataretrieval', 'IPython', 'rpy2'))

```

```{r set up workspace, warning=F, message=FALSE}
library(tidyverse)

#USGS and EPA dataset retrieval package
library(dataRetrieval) 
#click on "Packages" tab to see functions available in the dataRetrival package

#these are the USGS sites upstream from Honnedaga Lake, NY that we found in the browser
sites <- c('0134277112', '0134277114')

#detailed location information about the site
# readNWISsite(c('0134277112', '0134277114'))

#whatNWISdata displays the datasets available at each site
available <- whatNWISdata(siteNumber=c('0134277112', '0134277114'))
actual <- readNWISpCode(parameterCd = available$parm_cd) #interpret parameter codes
want <- c('00681', '00945', '50287', '50285') #we want: DOC, DSO4, DHg and DMeHg, 0060 is discharge
data <- readNWISqw(siteNumbers = sites, parameterCd=want) #get the data
Q <- readNWISdv(siteNumbers = sites, parameterCd='00060')
codes <- readNWISpCode(parameterCd = unique(data$parm_cd)) #confirms that we got what we wanted, shows UNITS!
View(data)

data[data$parm_cd=='00681',] %>% 
  ggplot(aes(x=sample_dt, y=result_va))+
  geom_point()+
  labs(x='Date', y='DOC')+
  theme_bw()

Q %>% ggplot(aes(x=Date, y=X_00060_00003, color=site_no))+
  geom_line()+
  labs(x='Date', y='Q (CFS)', color='Site')+
  theme_bw()

plot(x=Q$Date[Q$site_no==Q$site_no[1]], y=Q$X_00060_00003[Q$site_no==Q$site_no[1]], xlab = 'Date', ylab='Q (CFS)', type = 'l', col='red')
lines(x=Q$Date[Q$site_no==Q$site_no[2]], y=Q$X_00060_00003[Q$site_no==Q$site_no[2]], xlab = 'Date', ylab='Q (CFS)', type = 'l', col=1)

data$sample_dt <- lubridate::as_date(data$sample_dt)
  
```

In Terminal
$ pip install dataretrieval


```{python, python NWIS import}

import matplotlib.pyplot as plt
import pandas as pd
import dataretrieval.nwis as nwis

# get data from NWIS
site = '0134277112', '0134277114'

df12 = nwis.get_record( sites=site[0],  start='2011-05-16', end='2019-10-08', service='qwdata')

df14 = nwis.get_record( sites=site[1], start='2011-05-16', end='2019-10-08', service='dv')

df12b = nwis.get_qwdata(datetime_index = 'TRUE', site_no=site)


# plot discharge data

df14['00060_Mean'].plot(figsize=(12,7))
plt.ylabel('{} ({})'.format('Discharge','CFS'))
plt.xlabel('Date')
plt.title('Discharge Observation at USGS Gage 0134277114')
plt.show()
```

```{r}
NWIS <- reticulate::import('dataretrieval.nwis')
df12 <- NWIS$get_qwdata(datetime_index = T, site_no=py$site[1], parameterCd=want)
df12qw <- NWIS$get_record(sites = py$site[1], service = 'qwdata')
```


```{r look at python import}
view(py$df14)
tail(actual)
```

## Summarizing and visualizing
### Python

We have this data imported from NWIS, but there is too much for us to look at all at once.




```{python, results='asis'}
bysite=r.data.groupby(['site_no', 'parm_cd'])
summ=bysite['result_va'].describe()
summ
# summ.to_csv('pysumm.csv', index=False) export to csv doesn't work
print(summ.to_markdown)

```

In Jupityr notebook, this looks really good, but not if we are using R.  It also isn't very helpful for getting into R, because the index values get dropped.  One more line of of code will convert the index variables into column data.

```{python, results='asis'}
summ2=summ.reset_index(['site_no', 'parm_cd'])  #pick which ones to reset 
summ4=summ4.reset_index()                       #or do them all by leaving it blank
```

if we want to group by date, we need to convert 'Date' class in R to a character class.

```{r}
data$Date <- as.character(data$sample_dt)
```

then we can convert the character to a date in python

```{python}
data=r.data.set_index(pd.to_datetime(r.data.Date))


summ3=data.groupby(['site_no', 'parm_cd', pd.Grouper(freq="Y")])
summ4=summ3['result_va'].describe()
```

in R, the best way to visualize output is with the R-DT package

```{r}
library(DT)

DT::datatable(py$summ)
DT::datatable(py$summ2)
DT::datatable(py$summ4)
```

```{python}

from IPython.display import display

import rpy2.rinterface as rinterface
rinterface.initr()

from rpy2.robjects import pandas2ri
pandas2ri.activate()

import rpy2.robjects as robjects

r = robjects.r
pydisplaydf = r.source('pydisplaydf.r')[0]

display(pydisplaydf(summ))

```

###R 

```{r}
rsum <- data %>% group_by(site_no, parm_cd) %>% summarize(mean=mean(result_va, na.rm=T), std=sd(result_va, na.rm=T), max=max(result_va, na.rm=T), min=min(result_va, na.rm=T), n=n())


rsum %>% kable %>% kable_styling(bootstrap_options = c('striped', 'hover', 'responsive'))

py$summ2 %>% kable %>% kable_styling(bootstrap_options = c('striped', 'hover', 'responsive'))
```

